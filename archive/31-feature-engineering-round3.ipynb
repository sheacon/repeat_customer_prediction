{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9063660",
   "metadata": {},
   "source": [
    "# 31-feature-engineering-round3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c129da8-3451-4f8b-8833-6d020b4a7085",
   "metadata": {},
   "source": [
    "Notebook description: This notebook creates functions that split our time frames into different files and saves the files using the feature engineering that is generated in notebook 30. This notebook is for local paths, not ACCRE. Otherwise, is the same as round2 notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0949d17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "#import janitor\n",
    "import numpy as np\n",
    "import os\n",
    "# must install janitor package with the following shell command:\n",
    "# 'conda install -c conda-forge pyjanitor'\n",
    "\n",
    "# import label encoder\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68350ce4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'bridgestone-mubarak/fe_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4622e6e69d54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bridgestone-mubarak/fe_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bridgestone-mubarak/fe_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'bridgestone-mubarak/fe_data'"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"bridgestone-mubarak/fe_data\"):\n",
    "    os.mkdir(\"bridgestone-mubarak/fe_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e268c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = mega_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635ad06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unnamed_0_x</th>\n",
       "      <th>store_id</th>\n",
       "      <th>tran_id</th>\n",
       "      <th>date</th>\n",
       "      <th>article_id</th>\n",
       "      <th>indiv_id</th>\n",
       "      <th>vehicle_id</th>\n",
       "      <th>units</th>\n",
       "      <th>sales</th>\n",
       "      <th>prod_group_code</th>\n",
       "      <th>prod_group_desc</th>\n",
       "      <th>category_code</th>\n",
       "      <th>category_desc</th>\n",
       "      <th>segment_code</th>\n",
       "      <th>segment_desc</th>\n",
       "      <th>class_code</th>\n",
       "      <th>class_desc</th>\n",
       "      <th>discount_flag</th>\n",
       "      <th>cross_section</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>rim_size</th>\n",
       "      <th>state_code</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>msa_</th>\n",
       "      <th>unnamed_0_y</th>\n",
       "      <th>email_optin_ind</th>\n",
       "      <th>ah1_res_bus_indc</th>\n",
       "      <th>supp1_bus_pander</th>\n",
       "      <th>unnamed_0</th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>sub_model</th>\n",
       "      <th>model_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337934</td>\n",
       "      <td>990994590</td>\n",
       "      <td>2018-07-23</td>\n",
       "      <td>7001647</td>\n",
       "      <td>318422234.0</td>\n",
       "      <td>944814728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.55</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Services</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Heating/Cooling Systems</td>\n",
       "      <td>22008.0</td>\n",
       "      <td>Discount Heating/Cooling</td>\n",
       "      <td>22010.0</td>\n",
       "      <td>Discount Heating/Cooling</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MD</td>\n",
       "      <td>21740</td>\n",
       "      <td>HAGERSTOWN,</td>\n",
       "      <td>11239886</td>\n",
       "      <td>Y</td>\n",
       "      <td>R</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>337934</td>\n",
       "      <td>990994590</td>\n",
       "      <td>2018-07-23</td>\n",
       "      <td>7001715</td>\n",
       "      <td>318422234.0</td>\n",
       "      <td>944814728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-50.45</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Services</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Heating/Cooling Systems</td>\n",
       "      <td>105.0</td>\n",
       "      <td>Air Conditioning Services</td>\n",
       "      <td>371.0</td>\n",
       "      <td>A/C Inspection</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MD</td>\n",
       "      <td>21740</td>\n",
       "      <td>HAGERSTOWN,</td>\n",
       "      <td>11239886</td>\n",
       "      <td>Y</td>\n",
       "      <td>R</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>337934</td>\n",
       "      <td>990994590</td>\n",
       "      <td>2018-07-23</td>\n",
       "      <td>7096547</td>\n",
       "      <td>318422234.0</td>\n",
       "      <td>944814728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Services</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Heating/Cooling Systems</td>\n",
       "      <td>105.0</td>\n",
       "      <td>Air Conditioning Services</td>\n",
       "      <td>386.0</td>\n",
       "      <td>A/C System Leak Detection</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MD</td>\n",
       "      <td>21740</td>\n",
       "      <td>HAGERSTOWN,</td>\n",
       "      <td>11239886</td>\n",
       "      <td>Y</td>\n",
       "      <td>R</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>337934</td>\n",
       "      <td>990994590</td>\n",
       "      <td>2018-07-23</td>\n",
       "      <td>7001647</td>\n",
       "      <td>318422234.0</td>\n",
       "      <td>944814728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Services</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Heating/Cooling Systems</td>\n",
       "      <td>22008.0</td>\n",
       "      <td>Discount Heating/Cooling</td>\n",
       "      <td>22010.0</td>\n",
       "      <td>Discount Heating/Cooling</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MD</td>\n",
       "      <td>21740</td>\n",
       "      <td>HAGERSTOWN,</td>\n",
       "      <td>11239886</td>\n",
       "      <td>Y</td>\n",
       "      <td>R</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>337934</td>\n",
       "      <td>990994590</td>\n",
       "      <td>2018-07-23</td>\n",
       "      <td>7001715</td>\n",
       "      <td>318422234.0</td>\n",
       "      <td>944814728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Services</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Heating/Cooling Systems</td>\n",
       "      <td>105.0</td>\n",
       "      <td>Air Conditioning Services</td>\n",
       "      <td>371.0</td>\n",
       "      <td>A/C Inspection</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MD</td>\n",
       "      <td>21740</td>\n",
       "      <td>HAGERSTOWN,</td>\n",
       "      <td>11239886</td>\n",
       "      <td>Y</td>\n",
       "      <td>R</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unnamed_0_x store_id    tran_id        date  article_id     indiv_id  \\\n",
       "0            1   337934  990994590  2018-07-23     7001647  318422234.0   \n",
       "1            2   337934  990994590  2018-07-23     7001715  318422234.0   \n",
       "2            3   337934  990994590  2018-07-23     7096547  318422234.0   \n",
       "3            4   337934  990994590  2018-07-23     7001647  318422234.0   \n",
       "4            5   337934  990994590  2018-07-23     7001715  318422234.0   \n",
       "\n",
       "   vehicle_id  units  sales  prod_group_code prod_group_desc  category_code  \\\n",
       "0   944814728    0.0  -8.55              4.0        Services           78.0   \n",
       "1   944814728    0.0 -50.45              4.0        Services           78.0   \n",
       "2   944814728    0.0  10.00              4.0        Services           78.0   \n",
       "3   944814728    0.0   0.00              4.0        Services           78.0   \n",
       "4   944814728    0.0   0.00              4.0        Services           78.0   \n",
       "\n",
       "             category_desc  segment_code               segment_desc  \\\n",
       "0  Heating/Cooling Systems       22008.0   Discount Heating/Cooling   \n",
       "1  Heating/Cooling Systems         105.0  Air Conditioning Services   \n",
       "2  Heating/Cooling Systems         105.0  Air Conditioning Services   \n",
       "3  Heating/Cooling Systems       22008.0   Discount Heating/Cooling   \n",
       "4  Heating/Cooling Systems         105.0  Air Conditioning Services   \n",
       "\n",
       "   class_code                 class_desc discount_flag cross_section  \\\n",
       "0     22010.0   Discount Heating/Cooling             Y           NaN   \n",
       "1       371.0             A/C Inspection             Y           NaN   \n",
       "2       386.0  A/C System Leak Detection             N           NaN   \n",
       "3     22010.0   Discount Heating/Cooling             Y           NaN   \n",
       "4       371.0             A/C Inspection             Y           NaN   \n",
       "\n",
       "  aspect_ratio rim_size state_code zip_code         msa_  unnamed_0_y  \\\n",
       "0          NaN      NaN         MD    21740  HAGERSTOWN,     11239886   \n",
       "1          NaN      NaN         MD    21740  HAGERSTOWN,     11239886   \n",
       "2          NaN      NaN         MD    21740  HAGERSTOWN,     11239886   \n",
       "3          NaN      NaN         MD    21740  HAGERSTOWN,     11239886   \n",
       "4          NaN      NaN         MD    21740  HAGERSTOWN,     11239886   \n",
       "\n",
       "  email_optin_ind ah1_res_bus_indc supp1_bus_pander  unnamed_0 make model  \\\n",
       "0               Y                R                N        NaN  NaN   NaN   \n",
       "1               Y                R                N        NaN  NaN   NaN   \n",
       "2               Y                R                N        NaN  NaN   NaN   \n",
       "3               Y                R                N        NaN  NaN   NaN   \n",
       "4               Y                R                N        NaN  NaN   NaN   \n",
       "\n",
       "  sub_model  model_year  \n",
       "0       NaN         NaN  \n",
       "1       NaN         NaN  \n",
       "2       NaN         NaN  \n",
       "3       NaN         NaN  \n",
       "4       NaN         NaN  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9436da82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"month_year\"] = df[\"date\"].str[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c141807",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list = sorted(list(df[\"month_year\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307b0dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2015-04',\n",
       " '2015-05',\n",
       " '2015-06',\n",
       " '2015-07',\n",
       " '2015-08',\n",
       " '2015-09',\n",
       " '2015-10',\n",
       " '2015-11',\n",
       " '2015-12',\n",
       " '2016-01',\n",
       " '2016-02',\n",
       " '2016-03',\n",
       " '2016-04',\n",
       " '2016-05',\n",
       " '2016-06',\n",
       " '2016-07',\n",
       " '2016-08',\n",
       " '2016-09',\n",
       " '2016-10',\n",
       " '2016-11',\n",
       " '2016-12',\n",
       " '2017-01',\n",
       " '2017-02',\n",
       " '2017-03',\n",
       " '2017-04',\n",
       " '2017-05',\n",
       " '2017-06',\n",
       " '2017-07',\n",
       " '2017-08',\n",
       " '2017-09',\n",
       " '2017-10',\n",
       " '2017-11',\n",
       " '2017-12',\n",
       " '2018-01',\n",
       " '2018-02',\n",
       " '2018-03',\n",
       " '2018-04',\n",
       " '2018-05',\n",
       " '2018-06',\n",
       " '2018-07',\n",
       " '2018-08',\n",
       " '2018-09',\n",
       " '2018-10']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e1c01f",
   "metadata": {},
   "source": [
    "#### 2015 to 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a153dbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2015_17 = date_list[:date_list.index('2018-01')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f302af",
   "metadata": {},
   "source": [
    "#### 2015 to 2018-02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc2d56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2015_1802 = date_list[:date_list.index('2018-03')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff4b210",
   "metadata": {},
   "source": [
    "#### 2015 to 2018-04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18817a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2015_1804 = date_list[:date_list.index('2018-05')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060782a0",
   "metadata": {},
   "source": [
    "#### 2015 to 2018-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c72e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2015_1806 = date_list[:date_list.index('2018-07')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876209d9",
   "metadata": {},
   "source": [
    "#### 2015 to 2018-08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc21540",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2015_1808 = date_list[:date_list.index('2018-09')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e59b26f",
   "metadata": {},
   "source": [
    "#### 2015 to 2018-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b78646",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2015_1810 = date_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6d8284",
   "metadata": {},
   "source": [
    "#### Function for collecting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4efec79",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This should be used for everything except the 2015 to October 2018 data\n",
    "def data_collection(previous_months_list, response_month):\n",
    "    df1 = df[df['date'].str[:-3].isin(previous_months_list)].reset_index()\n",
    "    useless_columns = [\"unnamed_0\", \"unnamed_0_x\", \"unnamed_0_y\"]\n",
    "    for useless in useless_columns:\n",
    "        if useless in list(df1.columns):\n",
    "            df1 = df1.drop(useless, axis = 1)\n",
    "    dfc = df1.groupby(['indiv_id'\n",
    "                              ,'tran_id'\n",
    "                              ,'date'\n",
    "                              ,'prod_group_desc'\n",
    "                              ,'vehicle_id'], as_index = False).agg(\n",
    "        rows_collapsed = pd.NamedAgg(column='article_id', aggfunc='count')\n",
    "        ,sales_total = pd.NamedAgg(column='sales', aggfunc='sum')\n",
    "        ,model_year_avg = pd.NamedAgg(column='model_year', aggfunc='mean')\n",
    "        ,region = pd.NamedAgg(column='msa_', aggfunc='max'))\n",
    "    # create three additional columns in the dataframe \n",
    "    # each has a 1 or a 0 depending on what kind of product transaction it was\n",
    "    dfc['tires'] = np.where(dfc['prod_group_desc']== 'Tires', 1, 0)\n",
    "    dfc['services'] = np.where(dfc['prod_group_desc']== 'Services', 1, 0)\n",
    "    dfc['other'] = np.where(dfc['prod_group_desc']== 'Other', 1, 0)\n",
    "    \n",
    "    # add monthly variables\n",
    "    dfc['jan'] = np.where((dfc['date'].str[5:7].isin(['01']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['feb'] = np.where((dfc['date'].str[5:7].isin(['02']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['mar'] = np.where((dfc['date'].str[5:7].isin(['03']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['apr'] = np.where((dfc['date'].str[5:7].isin(['04']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['may'] = np.where((dfc['date'].str[5:7].isin(['05']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['jun'] = np.where((dfc['date'].str[5:7].isin(['06']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['jul'] = np.where((dfc['date'].str[5:7].isin(['07']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['aug'] = np.where((dfc['date'].str[5:7].isin(['08']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['sep'] = np.where((dfc['date'].str[5:7].isin(['09']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['oct'] = np.where((dfc['date'].str[5:7].isin(['10']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['nov'] = np.where((dfc['date'].str[5:7].isin(['11']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['dec'] = np.where((dfc['date'].str[5:7].isin(['12']) & dfc['tires'] == 1), 1, 0)\n",
    "    \n",
    "    # recast date as datetime\n",
    "    dfc['date'] = pd.to_datetime(dfc['date'], format = '%Y-%m-%d')\n",
    "\n",
    "    # add end date for each row (same)\n",
    "    response_date = response_month + \"-01\"\n",
    "    dfc['end_date'] = pd.to_datetime(response_date, format = '%Y-%m-%d')\n",
    "    \n",
    "    # add 'days_since' measure\n",
    "    # this is days since the transaction took place, from the perspective of 2018-01-01\n",
    "    dfc['days_since_any'] = (dfc['end_date'] - dfc['date']).dt.days\n",
    "    dfc['days_since_tires'] = np.where(dfc['tires']== 1, dfc['days_since_any'], None)\n",
    "    dfc['days_since_services'] = np.where(dfc['services']== 1, dfc['days_since_any'], None)\n",
    "    dfc['days_since_other'] = np.where(dfc['other']== 1, dfc['days_since_any'], None)\n",
    "    \n",
    "    # label encode region\n",
    "    le = LabelEncoder()\n",
    "    dfc.region = le.fit_transform(dfc.region)\n",
    "    \n",
    "    dfc2 = dfc.groupby(['indiv_id'], as_index = False).agg(\n",
    "        total_transaction = pd.NamedAgg(column='tran_id', aggfunc='count')\n",
    "        ,sales_total = pd.NamedAgg(column='sales_total', aggfunc='sum')\n",
    "        ,tire_purchases = pd.NamedAgg(column='tires', aggfunc='sum')\n",
    "        ,service_purchases = pd.NamedAgg(column='services', aggfunc='sum')\n",
    "        ,other_purchases = pd.NamedAgg(column='other', aggfunc='sum')\n",
    "        ,days_since_first_transaction = pd.NamedAgg(column='days_since_any', aggfunc='max')\n",
    "        ,days_since_last_transaction = pd.NamedAgg(column='days_since_any', aggfunc='min')\n",
    "        ,days_since_first_tire_purchase = pd.NamedAgg(column='days_since_tires', aggfunc='max')\n",
    "        ,days_since_last_tire_purchase = pd.NamedAgg(column='days_since_tires', aggfunc='min')\n",
    "        ,vehicle_count = pd.NamedAgg(column='vehicle_id', aggfunc='nunique')\n",
    "        ,model_year_avg = pd.NamedAgg(column='model_year_avg', aggfunc='mean')\n",
    "        ,region = pd.NamedAgg(column='region', aggfunc='max')\n",
    "        ,jan = pd.NamedAgg(column='jan', aggfunc='sum')\n",
    "        ,feb = pd.NamedAgg(column='feb', aggfunc='sum')\n",
    "        ,mar = pd.NamedAgg(column='mar', aggfunc='sum')\n",
    "        ,apr = pd.NamedAgg(column='apr', aggfunc='sum')\n",
    "        ,may = pd.NamedAgg(column='may', aggfunc='sum')\n",
    "        ,jun = pd.NamedAgg(column='jun', aggfunc='sum')\n",
    "        ,jul = pd.NamedAgg(column='jul', aggfunc='sum')\n",
    "        ,aug = pd.NamedAgg(column='aug', aggfunc='sum')\n",
    "        ,sep = pd.NamedAgg(column='sep', aggfunc='sum')\n",
    "        ,oct = pd.NamedAgg(column='oct', aggfunc='sum')\n",
    "        ,nov = pd.NamedAgg(column='nov', aggfunc='sum')\n",
    "        ,dec = pd.NamedAgg(column='dec', aggfunc='sum'))\n",
    "    # tire purchasing frequency\n",
    "    dfc2['tire_purchase_freq'] = dfc2['tire_purchases'] / dfc2['days_since_first_transaction']\n",
    "    dfc2['days_since_first_tire_purchase'] = dfc2['days_since_first_tire_purchase'].fillna(-1)\n",
    "    dfc2['days_since_last_tire_purchase'] = dfc2['days_since_last_tire_purchase'].fillna(-1)    \n",
    "    \n",
    "    # subsetting to 2018-01 and filtering for tire purchases\n",
    "    df_response = df[df['date'].str[:7].isin([response_month])].reset_index()\n",
    "    df_response = df_response[(df_response['prod_group_desc'] == 'Tires')]\n",
    "    purchaser_ids = df_response['indiv_id'].unique().tolist()\n",
    "    \n",
    "    # adding response column to feature dataset\n",
    "    dfc2['response'] = np.where(dfc2['indiv_id'].isin(purchaser_ids), 1, 0)\n",
    "    \n",
    "    return dfc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a8f05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This should be used for the 2015 to October 2018 data set\n",
    "def data_collection_special(previous_months_list):\n",
    "    df1 = df[df['date'].str[:-3].isin(previous_months_list)].reset_index()\n",
    "    useless_columns = [\"unnamed_0\", \"unnamed_0_x\", \"unnamed_0_y\"]\n",
    "    for useless in useless_columns:\n",
    "        if useless in list(df1.columns):\n",
    "            df1 = df1.drop(useless, axis = 1)\n",
    "    dfc = df1.groupby(['indiv_id'\n",
    "                              ,'tran_id'\n",
    "                              ,'date'\n",
    "                              ,'prod_group_desc'\n",
    "                              ,'vehicle_id'], as_index = False).agg(\n",
    "        rows_collapsed = pd.NamedAgg(column='article_id', aggfunc='count')\n",
    "        ,sales_total = pd.NamedAgg(column='sales', aggfunc='sum')\n",
    "        ,model_year_avg = pd.NamedAgg(column='model_year', aggfunc='mean')\n",
    "        ,region = pd.NamedAgg(column='msa_', aggfunc='max'))\n",
    "    # create three additional columns in the dataframe \n",
    "    # each has a 1 or a 0 depending on what kind of product transaction it was\n",
    "    dfc['tires'] = np.where(dfc['prod_group_desc']== 'Tires', 1, 0)\n",
    "    dfc['services'] = np.where(dfc['prod_group_desc']== 'Services', 1, 0)\n",
    "    dfc['other'] = np.where(dfc['prod_group_desc']== 'Other', 1, 0)\n",
    "    \n",
    "    # add monthly variables\n",
    "    dfc['jan'] = np.where((dfc['date'].str[5:7].isin(['01']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['feb'] = np.where((dfc['date'].str[5:7].isin(['02']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['mar'] = np.where((dfc['date'].str[5:7].isin(['03']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['apr'] = np.where((dfc['date'].str[5:7].isin(['04']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['may'] = np.where((dfc['date'].str[5:7].isin(['05']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['jun'] = np.where((dfc['date'].str[5:7].isin(['06']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['jul'] = np.where((dfc['date'].str[5:7].isin(['07']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['aug'] = np.where((dfc['date'].str[5:7].isin(['08']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['sep'] = np.where((dfc['date'].str[5:7].isin(['09']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['oct'] = np.where((dfc['date'].str[5:7].isin(['10']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['nov'] = np.where((dfc['date'].str[5:7].isin(['11']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['dec'] = np.where((dfc['date'].str[5:7].isin(['12']) & dfc['tires'] == 1), 1, 0)\n",
    "    \n",
    "    # recast date as datetime\n",
    "    dfc['date'] = pd.to_datetime(dfc['date'], format = '%Y-%m-%d')\n",
    "\n",
    "    # add end date for each row (same)\n",
    "    dfc['end_date'] = pd.to_datetime('2018-11-01', format = '%Y-%m-%d')\n",
    "    \n",
    "    # add 'days_since' measure\n",
    "    # this is days since the transaction took place, from the perspective of 2018-01-01\n",
    "    dfc['days_since_any'] = (dfc['end_date'] - dfc['date']).dt.days\n",
    "    dfc['days_since_tires'] = np.where(dfc['tires']== 1, dfc['days_since_any'], None)\n",
    "    dfc['days_since_services'] = np.where(dfc['services']== 1, dfc['days_since_any'], None)\n",
    "    dfc['days_since_other'] = np.where(dfc['other']== 1, dfc['days_since_any'], None)\n",
    "    \n",
    "    # label encode region\n",
    "    le = LabelEncoder()\n",
    "    dfc.region = le.fit_transform(dfc.region)\n",
    "    \n",
    "    dfc2 = dfc.groupby(['indiv_id'], as_index = False).agg(\n",
    "        total_transaction = pd.NamedAgg(column='tran_id', aggfunc='count')\n",
    "        ,sales_total = pd.NamedAgg(column='sales_total', aggfunc='sum')\n",
    "        ,tire_purchases = pd.NamedAgg(column='tires', aggfunc='sum')\n",
    "        ,service_purchases = pd.NamedAgg(column='services', aggfunc='sum')\n",
    "        ,other_purchases = pd.NamedAgg(column='other', aggfunc='sum')\n",
    "        ,days_since_first_transaction = pd.NamedAgg(column='days_since_any', aggfunc='max')\n",
    "        ,days_since_last_transaction = pd.NamedAgg(column='days_since_any', aggfunc='min')\n",
    "        ,days_since_first_tire_purchase = pd.NamedAgg(column='days_since_tires', aggfunc='max')\n",
    "        ,days_since_last_tire_purchase = pd.NamedAgg(column='days_since_tires', aggfunc='min')\n",
    "        ,vehicle_count = pd.NamedAgg(column='vehicle_id', aggfunc='nunique')\n",
    "        ,model_year_avg = pd.NamedAgg(column='model_year_avg', aggfunc='mean')\n",
    "       ,region = pd.NamedAgg(column='region', aggfunc='max')\n",
    "        ,jan = pd.NamedAgg(column='jan', aggfunc='sum')\n",
    "        ,feb = pd.NamedAgg(column='feb', aggfunc='sum')\n",
    "        ,mar = pd.NamedAgg(column='mar', aggfunc='sum')\n",
    "        ,apr = pd.NamedAgg(column='apr', aggfunc='sum')\n",
    "        ,may = pd.NamedAgg(column='may', aggfunc='sum')\n",
    "        ,jun = pd.NamedAgg(column='jun', aggfunc='sum')\n",
    "        ,jul = pd.NamedAgg(column='jul', aggfunc='sum')\n",
    "        ,aug = pd.NamedAgg(column='aug', aggfunc='sum')\n",
    "        ,sep = pd.NamedAgg(column='sep', aggfunc='sum')\n",
    "        ,oct = pd.NamedAgg(column='oct', aggfunc='sum')\n",
    "        ,nov = pd.NamedAgg(column='nov', aggfunc='sum')\n",
    "        ,dec = pd.NamedAgg(column='dec', aggfunc='sum'))\n",
    "\n",
    "    # tire purchasing frequency\n",
    "    dfc2['tire_purchase_freq'] = dfc2['tire_purchases'] / dfc2['days_since_first_transaction']\n",
    "    dfc2['days_since_first_tire_purchase'] = dfc2['days_since_first_tire_purchase'].fillna(-1)\n",
    "    dfc2['days_since_last_tire_purchase'] = dfc2['days_since_last_tire_purchase'].fillna(-1)    \n",
    "    \n",
    "    return dfc2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9742d4fa",
   "metadata": {},
   "source": [
    "#### Collecting data for 2015 - 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1967873",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_2015_17 = data_collection(d2015_17, '2018-01')\n",
    "d_2015_17.to_csv(\"fe_data/2015_17.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8e648d",
   "metadata": {},
   "source": [
    "#### Collecting data for 2015 - 2018-02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca8d9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2015_18_02 = data_collection(d2015_1802, '2018-03')\n",
    "df2015_18_02.to_csv(\"fe_data/2015_18_02.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8477ac",
   "metadata": {},
   "source": [
    "#### Collecting data for 2015 - 2018-04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b1965b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2015_18_04 = data_collection(d2015_1804, '2018-05')\n",
    "df2015_18_04.to_csv(\"fe_data/2015_18_04.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60758cd7",
   "metadata": {},
   "source": [
    "#### Collecting data for 2015 - 2018-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30efb6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2015_18_06 = data_collection(d2015_1806, '2018-07')\n",
    "df2015_18_06.to_csv(\"fe_data/2015_18_06.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3dc1a0",
   "metadata": {},
   "source": [
    "#### Collecting data for 2015 - 2018-08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d476e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2015_18_08 = data_collection(d2015_1808, '2018-09')\n",
    "df2015_18_08.to_csv(\"fe_data/2015_18_08.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df6bf52",
   "metadata": {},
   "source": [
    "#### Collecting data for 2015 - 2018-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728cfd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2015_18_10 = data_collection_special(d2015_1810)\n",
    "df2015_18_10.to_csv(\"fe_data/2015_18_10.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea8f94c-8ee6-4947-bd75-8ab9ebf202b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9063660",
   "metadata": {},
   "source": [
    "# 31-feature-engineering-round2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1204639f-c626-4788-99a0-ff7df3c08ad9",
   "metadata": {},
   "source": [
    "Notebook description: This notebook creates functions that split our time frames into different files and saves the files using the feature engineering that is generated in notebook 30. This notebook is for ACCRE paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0949d17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "#import janitor\n",
    "import numpy as np\n",
    "import os\n",
    "# must install janitor package with the following shell command:\n",
    "# 'conda install -c conda-forge pyjanitor'\n",
    "\n",
    "# import label encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68350ce4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/p_dsi/teams2022/team_1/fe_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-90a443252dc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/data/p_dsi/teams2022/team_1/fe_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/data/p_dsi/teams2022/team_1/fe_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/p_dsi/teams2022/team_1/fe_data'"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"/data/p_dsi/teams2022/team_1/fe_data\"):\n",
    "    os.mkdir(\"/data/p_dsi/teams2022/team_1/fe_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e268c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/data/p_dsi/teams2022/team_1/new_data/total_dataset.csv', sep = ',', skiprows=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635ad06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>store_id</th>\n",
       "      <th>tran_id</th>\n",
       "      <th>date</th>\n",
       "      <th>article_id</th>\n",
       "      <th>indiv_id</th>\n",
       "      <th>vehicle_id</th>\n",
       "      <th>units</th>\n",
       "      <th>sales</th>\n",
       "      <th>prod_group_code</th>\n",
       "      <th>...</th>\n",
       "      <th>rim_size</th>\n",
       "      <th>state_code</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>msa</th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>sub_model</th>\n",
       "      <th>model_year</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>11231</td>\n",
       "      <td>991578410</td>\n",
       "      <td>2018-09-25</td>\n",
       "      <td>7019488</td>\n",
       "      <td>298912276.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA</td>\n",
       "      <td>92404.0</td>\n",
       "      <td>RIVERSIDE,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "      <td>930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>11231</td>\n",
       "      <td>991578410</td>\n",
       "      <td>2018-09-25</td>\n",
       "      <td>7013645</td>\n",
       "      <td>298912276.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA</td>\n",
       "      <td>92404.0</td>\n",
       "      <td>RIVERSIDE,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "      <td>930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>136</td>\n",
       "      <td>745098</td>\n",
       "      <td>991098920</td>\n",
       "      <td>2018-09-08</td>\n",
       "      <td>7046930</td>\n",
       "      <td>266405778.0</td>\n",
       "      <td>970326107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MA</td>\n",
       "      <td>1864.0</td>\n",
       "      <td>BOSTON,MA</td>\n",
       "      <td>HONDA</td>\n",
       "      <td>CR-V EX</td>\n",
       "      <td>EX</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>137</td>\n",
       "      <td>745098</td>\n",
       "      <td>991098920</td>\n",
       "      <td>2018-09-08</td>\n",
       "      <td>7074810</td>\n",
       "      <td>266405778.0</td>\n",
       "      <td>970326107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MA</td>\n",
       "      <td>1864.0</td>\n",
       "      <td>BOSTON,MA</td>\n",
       "      <td>HONDA</td>\n",
       "      <td>CR-V EX</td>\n",
       "      <td>EX</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>138</td>\n",
       "      <td>20923</td>\n",
       "      <td>991456730</td>\n",
       "      <td>2018-09-12</td>\n",
       "      <td>7034622</td>\n",
       "      <td>290571671.0</td>\n",
       "      <td>929164614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MD</td>\n",
       "      <td>20601.0</td>\n",
       "      <td>WASHINGTON</td>\n",
       "      <td>HONDA</td>\n",
       "      <td>CR-V EX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  store_id    tran_id        date  article_id     indiv_id  \\\n",
       "0           6     11231  991578410  2018-09-25     7019488  298912276.0   \n",
       "1           7     11231  991578410  2018-09-25     7013645  298912276.0   \n",
       "2         136    745098  991098920  2018-09-08     7046930  266405778.0   \n",
       "3         137    745098  991098920  2018-09-08     7074810  266405778.0   \n",
       "4         138     20923  991456730  2018-09-12     7034622  290571671.0   \n",
       "\n",
       "   vehicle_id  units  sales  prod_group_code  ... rim_size  state_code  \\\n",
       "0           1    0.0   11.0              4.0  ...      NaN          CA   \n",
       "1           1    0.0    7.0              4.0  ...      NaN          CA   \n",
       "2   970326107    0.0    0.0              4.0  ...      NaN          MA   \n",
       "3   970326107    0.0    0.0              4.0  ...      NaN          MA   \n",
       "4   929164614    0.0   58.0              4.0  ...      NaN          MD   \n",
       "\n",
       "  zip_code         msa   make    model sub_model model_year  year month  \n",
       "0  92404.0  RIVERSIDE,    NaN      NaN       NaN        NaN  2018   930  \n",
       "1  92404.0  RIVERSIDE,    NaN      NaN       NaN        NaN  2018   930  \n",
       "2   1864.0   BOSTON,MA  HONDA  CR-V EX        EX     2011.0  2018   930  \n",
       "3   1864.0   BOSTON,MA  HONDA  CR-V EX        EX     2011.0  2018   930  \n",
       "4  20601.0  WASHINGTON  HONDA  CR-V EX       NaN     2012.0  2018   930  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9436da82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"month_year\"] = df[\"date\"].str[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c141807",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list = sorted(list(df[\"month_year\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307b0dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2015-04',\n",
       " '2015-05',\n",
       " '2015-06',\n",
       " '2015-07',\n",
       " '2015-08',\n",
       " '2015-09',\n",
       " '2015-10',\n",
       " '2015-11',\n",
       " '2015-12',\n",
       " '2016-01',\n",
       " '2016-02',\n",
       " '2016-03',\n",
       " '2016-04',\n",
       " '2016-05',\n",
       " '2016-06',\n",
       " '2016-07',\n",
       " '2016-08',\n",
       " '2016-09',\n",
       " '2016-10',\n",
       " '2016-11',\n",
       " '2016-12',\n",
       " '2017-01',\n",
       " '2017-02',\n",
       " '2017-03',\n",
       " '2017-04',\n",
       " '2017-05',\n",
       " '2017-06',\n",
       " '2017-07',\n",
       " '2017-08',\n",
       " '2017-09',\n",
       " '2017-10',\n",
       " '2017-11',\n",
       " '2017-12',\n",
       " '2018-01',\n",
       " '2018-02',\n",
       " '2018-03',\n",
       " '2018-04',\n",
       " '2018-05',\n",
       " '2018-06',\n",
       " '2018-07',\n",
       " '2018-08',\n",
       " '2018-09',\n",
       " '2018-10']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e1c01f",
   "metadata": {},
   "source": [
    "#### 2015 to 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a153dbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2015_17 = date_list[:date_list.index('2018-01')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f302af",
   "metadata": {},
   "source": [
    "#### 2015 to 2018-02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc2d56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2015_1802 = date_list[:date_list.index('2018-03')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff4b210",
   "metadata": {},
   "source": [
    "#### 2015 to 2018-04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18817a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2015_1804 = date_list[:date_list.index('2018-05')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060782a0",
   "metadata": {},
   "source": [
    "#### 2015 to 2018-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c72e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2015_1806 = date_list[:date_list.index('2018-07')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876209d9",
   "metadata": {},
   "source": [
    "#### 2015 to 2018-08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc21540",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2015_1808 = date_list[:date_list.index('2018-09')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e59b26f",
   "metadata": {},
   "source": [
    "#### 2015 to 2018-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b78646",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2015_1810 = date_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6d8284",
   "metadata": {},
   "source": [
    "#### Function for collecting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4efec79",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This should be used for everything except the 2015 to October 2018 data\n",
    "def data_collection(previous_months_list, response_month):\n",
    "    df1 = df[df['date'].str[:-3].isin(previous_months_list)].reset_index()\n",
    "    useless_columns = [\"unnamed_0\", \"unnamed_0_x\", \"unnamed_0_y\"]\n",
    "    for useless in useless_columns:\n",
    "        if useless in list(df1.columns):\n",
    "            df1 = df1.drop(useless, axis = 1)\n",
    "    dfc = df1.groupby(['indiv_id'\n",
    "                              ,'tran_id'\n",
    "                              ,'date'\n",
    "                              ,'prod_group_desc'\n",
    "                              ,'vehicle_id'], as_index = False).agg(\n",
    "        rows_collapsed = pd.NamedAgg(column='article_id', aggfunc='count')\n",
    "        ,sales_total = pd.NamedAgg(column='sales', aggfunc='sum')\n",
    "        ,model_year_avg = pd.NamedAgg(column='model_year', aggfunc='mean')\n",
    "        ,region = pd.NamedAgg(column='msa_', aggfunc='max'))\n",
    "    # create three additional columns in the dataframe \n",
    "    # each has a 1 or a 0 depending on what kind of product transaction it was\n",
    "    dfc['tires'] = np.where(dfc['prod_group_desc']== 'Tires', 1, 0)\n",
    "    dfc['services'] = np.where(dfc['prod_group_desc']== 'Services', 1, 0)\n",
    "    dfc['other'] = np.where(dfc['prod_group_desc']== 'Other', 1, 0)\n",
    "    \n",
    "    # add monthly variables\n",
    "    dfc['jan'] = np.where((dfc['date'].str[5:7].isin(['01']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['feb'] = np.where((dfc['date'].str[5:7].isin(['02']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['mar'] = np.where((dfc['date'].str[5:7].isin(['03']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['apr'] = np.where((dfc['date'].str[5:7].isin(['04']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['may'] = np.where((dfc['date'].str[5:7].isin(['05']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['jun'] = np.where((dfc['date'].str[5:7].isin(['06']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['jul'] = np.where((dfc['date'].str[5:7].isin(['07']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['aug'] = np.where((dfc['date'].str[5:7].isin(['08']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['sep'] = np.where((dfc['date'].str[5:7].isin(['09']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['oct'] = np.where((dfc['date'].str[5:7].isin(['10']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['nov'] = np.where((dfc['date'].str[5:7].isin(['11']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['dec'] = np.where((dfc['date'].str[5:7].isin(['12']) & dfc['tires'] == 1), 1, 0)\n",
    "    \n",
    "    # recast date as datetime\n",
    "    dfc['date'] = pd.to_datetime(dfc['date'], format = '%Y-%m-%d')\n",
    "\n",
    "    # add end date for each row (same)\n",
    "    response_date = response_month + \"-01\"\n",
    "    dfc['end_date'] = pd.to_datetime(response_date, format = '%Y-%m-%d')\n",
    "    \n",
    "    # add 'days_since' measure\n",
    "    # this is days since the transaction took place, from the perspective of 2018-01-01\n",
    "    dfc['days_since_any'] = (dfc['end_date'] - dfc['date']).dt.days\n",
    "    dfc['days_since_tires'] = np.where(dfc['tires']== 1, dfc['days_since_any'], None)\n",
    "    dfc['days_since_services'] = np.where(dfc['services']== 1, dfc['days_since_any'], None)\n",
    "    dfc['days_since_other'] = np.where(dfc['other']== 1, dfc['days_since_any'], None)\n",
    "    \n",
    "    # label encode the region column\n",
    "    le = LabelEncoder()\n",
    "    dfc.region = le.fit_transform(dfc.region)\n",
    "\n",
    "    dfc2 = dfc.groupby(['indiv_id'], as_index = False).agg(\n",
    "        total_transaction = pd.NamedAgg(column='tran_id', aggfunc='count')\n",
    "        ,sales_total = pd.NamedAgg(column='sales_total', aggfunc='sum')\n",
    "        ,tire_purchases = pd.NamedAgg(column='tires', aggfunc='sum')\n",
    "        ,service_purchases = pd.NamedAgg(column='services', aggfunc='sum')\n",
    "        ,other_purchases = pd.NamedAgg(column='other', aggfunc='sum')\n",
    "        ,days_since_first_transaction = pd.NamedAgg(column='days_since_any', aggfunc='max')\n",
    "        ,days_since_last_transaction = pd.NamedAgg(column='days_since_any', aggfunc='min')\n",
    "        ,days_since_first_tire_purchase = pd.NamedAgg(column='days_since_tires', aggfunc='max')\n",
    "        ,days_since_last_tire_purchase = pd.NamedAgg(column='days_since_tires', aggfunc='min')\n",
    "        ,vehicle_count = pd.NamedAgg(column='vehicle_id', aggfunc='nunique')\n",
    "        ,model_year_avg = pd.NamedAgg(column='model_year_avg', aggfunc='mean')\n",
    "        ,region = pd.NamedAgg(column='region', aggfunc='max')\n",
    "        ,jan = pd.NamedAgg(column='jan', aggfunc='sum')\n",
    "        ,feb = pd.NamedAgg(column='feb', aggfunc='sum')\n",
    "        ,mar = pd.NamedAgg(column='mar', aggfunc='sum')\n",
    "        ,apr = pd.NamedAgg(column='apr', aggfunc='sum')\n",
    "        ,may = pd.NamedAgg(column='may', aggfunc='sum')\n",
    "        ,jun = pd.NamedAgg(column='jun', aggfunc='sum')\n",
    "        ,jul = pd.NamedAgg(column='jul', aggfunc='sum')\n",
    "        ,aug = pd.NamedAgg(column='aug', aggfunc='sum')\n",
    "        ,sep = pd.NamedAgg(column='sep', aggfunc='sum')\n",
    "        ,oct = pd.NamedAgg(column='oct', aggfunc='sum')\n",
    "        ,nov = pd.NamedAgg(column='nov', aggfunc='sum')\n",
    "        ,dec = pd.NamedAgg(column='dec', aggfunc='sum'))\n",
    "    # tire purchasing frequency\n",
    "    dfc2['tire_purchase_freq'] = dfc2['tire_purchases'] / dfc2['days_since_first_transaction']\n",
    "    dfc2['days_since_first_tire_purchase'] = dfc2['days_since_first_tire_purchase'].fillna(-1)\n",
    "    dfc2['days_since_last_tire_purchase'] = dfc2['days_since_last_tire_purchase'].fillna(-1)    \n",
    "    \n",
    "    # subsetting to 2018-01 and filtering for tire purchases\n",
    "    df_response = df[df['date'].str[:7].isin([response_month])].reset_index()\n",
    "    df_response = df_response[(df_response['prod_group_desc'] == 'Tires')]\n",
    "    purchaser_ids = df_response['indiv_id'].unique().tolist()\n",
    "    \n",
    "    # adding response column to feature dataset\n",
    "    dfc2['response'] = np.where(dfc2['indiv_id'].isin(purchaser_ids), 1, 0)\n",
    "    \n",
    "    return dfc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a8f05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This should be used for the 2015 to October 2018 data set\n",
    "def data_collection_special(previous_months_list):\n",
    "    df1 = df[df['date'].str[:-3].isin(previous_months_list)].reset_index()\n",
    "    useless_columns = [\"unnamed_0\", \"unnamed_0_x\", \"unnamed_0_y\"]\n",
    "    for useless in useless_columns:\n",
    "        if useless in list(df1.columns):\n",
    "            df1 = df1.drop(useless, axis = 1)\n",
    "    dfc = df1.groupby(['indiv_id'\n",
    "                              ,'tran_id'\n",
    "                              ,'date'\n",
    "                              ,'prod_group_desc'\n",
    "                              ,'vehicle_id'], as_index = False).agg(\n",
    "        rows_collapsed = pd.NamedAgg(column='article_id', aggfunc='count')\n",
    "        ,sales_total = pd.NamedAgg(column='sales', aggfunc='sum')\n",
    "        ,model_year_avg = pd.NamedAgg(column='model_year', aggfunc='mean')\n",
    "        ,region = pd.NamedAgg(column='msa_', aggfunc='max'))\n",
    "    # create three additional columns in the dataframe \n",
    "    # each has a 1 or a 0 depending on what kind of product transaction it was\n",
    "    dfc['tires'] = np.where(dfc['prod_group_desc']== 'Tires', 1, 0)\n",
    "    dfc['services'] = np.where(dfc['prod_group_desc']== 'Services', 1, 0)\n",
    "    dfc['other'] = np.where(dfc['prod_group_desc']== 'Other', 1, 0)\n",
    "        \n",
    "    # add monthly variables\n",
    "    dfc['jan'] = np.where((dfc['date'].str[5:7].isin(['01']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['feb'] = np.where((dfc['date'].str[5:7].isin(['02']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['mar'] = np.where((dfc['date'].str[5:7].isin(['03']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['apr'] = np.where((dfc['date'].str[5:7].isin(['04']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['may'] = np.where((dfc['date'].str[5:7].isin(['05']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['jun'] = np.where((dfc['date'].str[5:7].isin(['06']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['jul'] = np.where((dfc['date'].str[5:7].isin(['07']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['aug'] = np.where((dfc['date'].str[5:7].isin(['08']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['sep'] = np.where((dfc['date'].str[5:7].isin(['09']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['oct'] = np.where((dfc['date'].str[5:7].isin(['10']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['nov'] = np.where((dfc['date'].str[5:7].isin(['11']) & dfc['tires'] == 1), 1, 0)\n",
    "    dfc['dec'] = np.where((dfc['date'].str[5:7].isin(['12']) & dfc['tires'] == 1), 1, 0)\n",
    "    \n",
    "    # recast date as datetime\n",
    "    dfc['date'] = pd.to_datetime(dfc['date'], format = '%Y-%m-%d')\n",
    "\n",
    "    # add end date for each row (same)\n",
    "    dfc['end_date'] = pd.to_datetime('2018-11-01', format = '%Y-%m-%d')\n",
    "    \n",
    "    # add 'days_since' measure\n",
    "    # this is days since the transaction took place, from the perspective of 2018-01-01\n",
    "    dfc['days_since_any'] = (dfc['end_date'] - dfc['date']).dt.days\n",
    "    dfc['days_since_tires'] = np.where(dfc['tires']== 1, dfc['days_since_any'], None)\n",
    "    dfc['days_since_services'] = np.where(dfc['services']== 1, dfc['days_since_any'], None)\n",
    "    dfc['days_since_other'] = np.where(dfc['other']== 1, dfc['days_since_any'], None)\n",
    "    \n",
    "    # label encode the region column\n",
    "    le = LabelEncoder()\n",
    "    dfc.region = le.fit_transform(dfc.region)\n",
    "    \n",
    "    dfc2 = dfc.groupby(['indiv_id'], as_index = False).agg(\n",
    "        total_transaction = pd.NamedAgg(column='tran_id', aggfunc='count')\n",
    "        ,sales_total = pd.NamedAgg(column='sales_total', aggfunc='sum')\n",
    "        ,tire_purchases = pd.NamedAgg(column='tires', aggfunc='sum')\n",
    "        ,service_purchases = pd.NamedAgg(column='services', aggfunc='sum')\n",
    "        ,other_purchases = pd.NamedAgg(column='other', aggfunc='sum')\n",
    "        ,days_since_first_transaction = pd.NamedAgg(column='days_since_any', aggfunc='max')\n",
    "        ,days_since_last_transaction = pd.NamedAgg(column='days_since_any', aggfunc='min')\n",
    "        ,days_since_first_tire_purchase = pd.NamedAgg(column='days_since_tires', aggfunc='max')\n",
    "        ,days_since_last_tire_purchase = pd.NamedAgg(column='days_since_tires', aggfunc='min')\n",
    "        ,vehicle_count = pd.NamedAgg(column='vehicle_id', aggfunc='nunique')\n",
    "        ,model_year_avg = pd.NamedAgg(column='model_year_avg', aggfunc='mean')\n",
    "        ,region = pd.NamedAgg(column='region', aggfunc='max')\n",
    "        ,jan = pd.NamedAgg(column='jan', aggfunc='sum')\n",
    "        ,feb = pd.NamedAgg(column='feb', aggfunc='sum')\n",
    "        ,mar = pd.NamedAgg(column='mar', aggfunc='sum')\n",
    "        ,apr = pd.NamedAgg(column='apr', aggfunc='sum')\n",
    "        ,may = pd.NamedAgg(column='may', aggfunc='sum')\n",
    "        ,jun = pd.NamedAgg(column='jun', aggfunc='sum')\n",
    "        ,jul = pd.NamedAgg(column='jul', aggfunc='sum')\n",
    "        ,aug = pd.NamedAgg(column='aug', aggfunc='sum')\n",
    "        ,sep = pd.NamedAgg(column='sep', aggfunc='sum')\n",
    "        ,oct = pd.NamedAgg(column='oct', aggfunc='sum')\n",
    "        ,nov = pd.NamedAgg(column='nov', aggfunc='sum')\n",
    "        ,dec = pd.NamedAgg(column='dec', aggfunc='sum'))\n",
    "\n",
    "    # tire purchasing frequency\n",
    "    dfc2['tire_purchase_freq'] = dfc2['tire_purchases'] / dfc2['days_since_first_transaction']\n",
    "    dfc2['days_since_first_tire_purchase'] = dfc2['days_since_first_tire_purchase'].fillna(-1)\n",
    "    dfc2['days_since_last_tire_purchase'] = dfc2['days_since_last_tire_purchase'].fillna(-1)    \n",
    "    \n",
    "    return dfc2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9742d4fa",
   "metadata": {},
   "source": [
    "#### Collecting data for 2015 - 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1967873",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_2015_17 = data_collection(d2015_17, '2018-01')\n",
    "d_2015_17.to_csv(\"/data/p_dsi/teams2022/team_1/fe_data/2015_17.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8e648d",
   "metadata": {},
   "source": [
    "#### Collecting data for 2015 - 2018-02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca8d9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2015_18_02 = data_collection(d2015_1802, '2018-03')\n",
    "df2015_18_02.to_csv(\"/data/p_dsi/teams2022/team_1/fe_data/2015_18_02.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8477ac",
   "metadata": {},
   "source": [
    "#### Collecting data for 2015 - 2018-04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b1965b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2015_18_04 = data_collection(d2015_1804, '2018-05')\n",
    "df2015_18_04.to_csv(\"/data/p_dsi/teams2022/team_1/fe_data/2015_18_04.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60758cd7",
   "metadata": {},
   "source": [
    "#### Collecting data for 2015 - 2018-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30efb6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2015_18_06 = data_collection(d2015_1806, '2018-07')\n",
    "df2015_18_06.to_csv(\"/data/p_dsi/teams2022/team_1/fe_data/2015_18_06.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3dc1a0",
   "metadata": {},
   "source": [
    "#### Collecting data for 2015 - 2018-08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d476e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2015_18_08 = data_collection(d2015_1808, '2018-09')\n",
    "df2015_18_08.to_csv(\"/data/p_dsi/teams2022/team_1/fe_data/2015_18_08.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df6bf52",
   "metadata": {},
   "source": [
    "#### Collecting data for 2015 - 2018-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728cfd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2015_18_10 = data_collection_special(d2015_1810)\n",
    "df2015_18_10.to_csv(\"/data/p_dsi/teams2022/team_1/fe_data/2015_18_10.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea8f94c-8ee6-4947-bd75-8ab9ebf202b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

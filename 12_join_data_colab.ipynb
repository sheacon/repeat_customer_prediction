{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sheacon/repeat_customers/blob/main/12_join_full_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8u1higzYIln_"
      },
      "source": [
        "# Join Data\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check system specs\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print('Connected to a GPU')\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime: {:.1f} gigabytes of available RAM'.format(ram_gb))\n",
        "else:\n",
        "  print('Using a high-RAM runtime: {:.1f} gigabytes of available RAM'.format(ram_gb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xojTL10R1AQt",
        "outputId": "fd816b4b-4a6f-488e-fe6b-bde592aec42a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not connected to a GPU\n",
            "Using a high-RAM runtime: 54.8 gigabytes of available RAM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyjanitor==0.23.1"
      ],
      "metadata": {
        "id": "dU1caunPyrcL",
        "outputId": "ff6ada81-fc0d-4666-8969-cbcd74c37d7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyjanitor==0.23.1 in /usr/local/lib/python3.8/dist-packages (0.23.1)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.8/dist-packages (from pyjanitor==0.23.1) (5.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from pyjanitor==0.23.1) (1.7.3)\n",
            "Requirement already satisfied: pandas-flavor in /usr/local/lib/python3.8/dist-packages (from pyjanitor==0.23.1) (0.3.0)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.8/dist-packages (from pyjanitor==0.23.1) (0.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from multipledispatch->pyjanitor==0.23.1) (1.15.0)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.8/dist-packages (from pandas-flavor->pyjanitor==0.23.1) (1.3.5)\n",
            "Requirement already satisfied: lazy-loader==0.1rc2 in /usr/local/lib/python3.8/dist-packages (from pandas-flavor->pyjanitor==0.23.1) (0.1rc2)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.8/dist-packages (from pandas-flavor->pyjanitor==0.23.1) (2022.12.0)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy->pyjanitor==0.23.1) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.23->pandas-flavor->pyjanitor==0.23.1) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.23->pandas-flavor->pyjanitor==0.23.1) (2.8.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.8/dist-packages (from xarray->pandas-flavor->pyjanitor==0.23.1) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=21.3->xarray->pandas-flavor->pyjanitor==0.23.1) (3.0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "689iQwrFIloB"
      },
      "outputs": [],
      "source": [
        "# import packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import janitor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data, Except Sales"
      ],
      "metadata": {
        "id": "MPxVQNulb1HI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "     \n",
        "# navigate to directory\n",
        "%cd /content/gdrive/MyDrive/Projects/repeat_customers/data"
      ],
      "metadata": {
        "id": "llahQjbBIyJG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e79b886-3c4b-4cff-9e92-d03a5a29b639"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/MyDrive/Projects/repeat_customers/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cU9IA-2GIloD"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('processed/'):\n",
        "    os.mkdir('processed/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read individuals\n",
        "# set int32 and category dtypes for memory efficiency\n",
        "col_list = ['MZB_INDIV_ID','EMAIL_OPTIN_IND','AH1_RES_BUS_INDC','SUPP1_BUS_PANDER']\n",
        "individuals = pd.read_csv('raw/individual.csv'\n",
        "                          ,sep=','\n",
        "                          ,usecols=col_list\n",
        "                          ,dtype = {'MZB_INDIV_ID':np.int32\n",
        "                                    ,'EMAIL_OPTIN_IND':'category'\n",
        "                                    ,'AH1_RES_BUS_INDC':'category'\n",
        "                                    ,'SUPP1_BUS_PANDER':'category'} \n",
        "                         ).clean_names()\n",
        "individuals.rename(columns={'mzb_indiv_id':'indiv_id'}, inplace=True)\n",
        "\n",
        "print(individuals.info())\n",
        "print(individuals.nunique())"
      ],
      "metadata": {
        "id": "BxRbBmiRVsYi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca7759ad-5e49-469e-e9f3-76254bac1d21"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 16834962 entries, 0 to 16834961\n",
            "Data columns (total 4 columns):\n",
            " #   Column            Dtype   \n",
            "---  ------            -----   \n",
            " 0   indiv_id          int32   \n",
            " 1   email_optin_ind   category\n",
            " 2   ah1_res_bus_indc  category\n",
            " 3   supp1_bus_pander  category\n",
            "dtypes: category(3), int32(1)\n",
            "memory usage: 112.4 MB\n",
            "None\n",
            "indiv_id            16834962\n",
            "email_optin_ind            3\n",
            "ah1_res_bus_indc           3\n",
            "supp1_bus_pander           2\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read products\n",
        "col_list = ['ARTICLE_ID', 'PROD_GROUP_CODE', 'PROD_GROUP_DESC', 'CATEGORY_CODE',\n",
        "            'CATEGORY_DESC', 'SEGMENT_CODE', 'SEGMENT_DESC', 'CLASS_CODE',\n",
        "            'CLASS_DESC', 'DISCOUNT_FLAG', 'CROSS_SECTION', 'ASPECT_RATIO',\n",
        "            'RIM_SIZE']\n",
        "products = pd.read_csv('raw/product.csv'\n",
        "                        ,sep='|'\n",
        "                        ,usecols=col_list\n",
        "                        ,dtype = {'ARTICLE_ID':np.int32, 'PROD_GROUP_CODE':'category'\n",
        "                                , 'PROD_GROUP_DESC':'category', 'CATEGORY_CODE':'category'\n",
        "                                ,'CATEGORY_DESC':'category', 'SEGMENT_CODE':'category'\n",
        "                                , 'SEGMENT_DESC':'category', 'CLASS_CODE':'category'\n",
        "                                , 'CLASS_DESC':'category', 'DISCOUNT_FLAG':'category'\n",
        "                                , 'CROSS_SECTION':'category', 'ASPECT_RATIO':'category',\n",
        "                                  'RIM_SIZE':'category'}\n",
        "                        ).clean_names()\n",
        "products.info()\n",
        "print(products.nunique())"
      ],
      "metadata": {
        "id": "mAx497vIYpPw",
        "outputId": "36897430-244b-486c-eb2d-43ac17c6b71d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 56842 entries, 0 to 56841\n",
            "Data columns (total 13 columns):\n",
            " #   Column           Non-Null Count  Dtype   \n",
            "---  ------           --------------  -----   \n",
            " 0   article_id       56842 non-null  int32   \n",
            " 1   prod_group_code  56818 non-null  category\n",
            " 2   prod_group_desc  56818 non-null  category\n",
            " 3   category_code    56818 non-null  category\n",
            " 4   category_desc    56818 non-null  category\n",
            " 5   segment_code     56818 non-null  category\n",
            " 6   segment_desc     56818 non-null  category\n",
            " 7   class_code       56818 non-null  category\n",
            " 8   class_desc       56818 non-null  category\n",
            " 9   discount_flag    56818 non-null  category\n",
            " 10  cross_section    35670 non-null  category\n",
            " 11  aspect_ratio     35665 non-null  category\n",
            " 12  rim_size         35504 non-null  category\n",
            "dtypes: category(12), int32(1)\n",
            "memory usage: 1.1 MB\n",
            "article_id         56842\n",
            "prod_group_code        3\n",
            "prod_group_desc        3\n",
            "category_code         18\n",
            "category_desc         18\n",
            "segment_code          64\n",
            "segment_desc          65\n",
            "class_code           195\n",
            "class_desc           190\n",
            "discount_flag          3\n",
            "cross_section        195\n",
            "aspect_ratio          58\n",
            "rim_size              52\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read stores\n",
        "col_list = ['STORE_ID','STATE_CODE','ZIP_CODE','MSA']\n",
        "stores = pd.read_csv('raw/store.csv'\n",
        "                      ,sep='|'\n",
        "                      ,usecols=col_list\n",
        "                      ,dtype = {'STORE_ID':'category'\n",
        "                                ,'STATE_CODE':'category'\n",
        "                                ,'ZIP_CODE':'category'\n",
        "                                ,'MSA':'category'}\n",
        "                      ).clean_names()\n",
        "stores.info()\n",
        "print(stores.nunique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tptbwSQ-aqu5",
        "outputId": "6cca69c0-313f-48db-b035-9d8499905f60"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2814 entries, 0 to 2813\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count  Dtype   \n",
            "---  ------      --------------  -----   \n",
            " 0   store_id    2814 non-null   category\n",
            " 1   state_code  2814 non-null   category\n",
            " 2   zip_code    2814 non-null   category\n",
            " 3   msa         2309 non-null   category\n",
            "dtypes: category(4)\n",
            "memory usage: 201.0 KB\n",
            "store_id      2814\n",
            "state_code      48\n",
            "zip_code      2374\n",
            "msa            321\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read vehicles\n",
        "col_list = ['VEHICLE_ID','MAKE','MODEL','SUB_MODEL','MODEL_YEAR']\n",
        "vehicles = pd.read_csv('raw/vehicle.csv'\n",
        "                        ,sep='|'\n",
        "                        ,usecols=col_list\n",
        "                        ,dtype = {'VEHICLE_ID':np.int32\n",
        "                                  ,'MAKE':'category'\n",
        "                                  ,'MODEL':'category'\n",
        "                                  ,'SUB_MODEL':'category'\n",
        "                                  ,'MODEL_YEAR':np.int16}\n",
        "                        ).clean_names()\n",
        "vehicles.info()\n",
        "print(vehicles.nunique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJMHl2pfbmqb",
        "outputId": "39c604a4-ee61-4296-ee0e-9e291821175a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27854109 entries, 0 to 27854108\n",
            "Data columns (total 5 columns):\n",
            " #   Column      Dtype   \n",
            "---  ------      -----   \n",
            " 0   vehicle_id  int32   \n",
            " 1   make        category\n",
            " 2   model       category\n",
            " 3   sub_model   category\n",
            " 4   model_year  int16   \n",
            "dtypes: category(3), int16(1), int32(1)\n",
            "memory usage: 319.9 MB\n",
            "vehicle_id    27854109\n",
            "make              5064\n",
            "model            22573\n",
            "sub_model         9206\n",
            "model_year         196\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Sales Data"
      ],
      "metadata": {
        "id": "rEAyXa7Cc7I5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create list of sales files\n",
        "sales_files = [i for i in os.listdir('raw/') if 'sales_' in i]\n",
        "\n",
        "# column list\n",
        "col_list = ['STORE_ID','TRAN_ID','DATE','ARTICLE_ID','INDIV_ID','VEHICLE_ID','UNITS','SALES']"
      ],
      "metadata": {
        "id": "fn6BQbca38Vj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# date_parser = lambda dates : pd.datetime(dates, '%Y-%m-%d')"
      ],
      "metadata": {
        "id": "yegBmr7EeIaO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load initial sales file\n",
        "df = pd.read_csv('raw/' + sales_files[0]\n",
        "                  ,sep='|'\n",
        "                  ,usecols=col_list\n",
        "                  #,parse_dates=['DATE']\n",
        "                  #,date_parser=date_parser\n",
        "                  ,dtype = {'STORE_ID':'category'\n",
        "                            ,'TRAN_ID':np.int32\n",
        "                            ,'DATE':'category'\n",
        "                            ,'ARTICLE_ID':np.int32\n",
        "                            ,'VEHICLE_ID':np.int32\n",
        "                            ,'UNITS':np.int8\n",
        "                            ,'SALES':np.float16\n",
        "                            ,'INDIV_ID':np.float16 # int32 throws error claiming float value\n",
        "                            }\n",
        "                 ).clean_names()\n",
        "df.info()\n",
        "print(df.nunique())\n",
        "print('df memory: ',round(df.memory_usage(deep=True).sum()/1073741824,2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlJZGnaKc-Jk",
        "outputId": "a8bed666-c7ff-4ce3-d68b-4def212b1bd4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 14804703 entries, 0 to 14804702\n",
            "Data columns (total 8 columns):\n",
            " #   Column      Dtype   \n",
            "---  ------      -----   \n",
            " 0   store_id    category\n",
            " 1   tran_id     int32   \n",
            " 2   date        category\n",
            " 3   article_id  int32   \n",
            " 4   indiv_id    float16 \n",
            " 5   vehicle_id  int32   \n",
            " 6   units       int8    \n",
            " 7   sales       float16 \n",
            "dtypes: category(2), float16(2), int32(3), int8(1)\n",
            "memory usage: 282.5 MB\n",
            "store_id         2204\n",
            "tran_id        309871\n",
            "date               30\n",
            "article_id       8533\n",
            "indiv_id            1\n",
            "vehicle_id    1321780\n",
            "units             107\n",
            "sales           15266\n",
            "dtype: int64\n",
            "df memory:  0.28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Memory Solutions\n",
        "- loop reads into separate df's, concat all at once: https://www.terality.com/post/pandas-concat-vs-append\n",
        "- parquet by chunk: https://www.confessionsofadataguy.com/solving-the-memory-hungry-pandas-concat-problem/"
      ],
      "metadata": {
        "id": "0s5M9MmEB_uk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# method 1: read all and then append all at once\n",
        "\n",
        "sales_dfs = []\n",
        "sales_dfs['0'] = df\n",
        "\n",
        "for file in sales_files[1:]:\n",
        "\n",
        "  sales_to_append = pd.read_csv('raw/' + file\n",
        "                                ,sep='|'\n",
        "                                ,usecols=col_list\n",
        "                                #,parse_dates=['DATE']\n",
        "                                #,date_parser=date_parser\n",
        "                                ,dtype = {'STORE_ID':'category'\n",
        "                                          ,'TRAN_ID':np.int32\n",
        "                                          ,'DATE':'category'\n",
        "                                          ,'ARTICLE_ID':np.int32\n",
        "                                          ,'VEHICLE_ID':np.int32\n",
        "                                          ,'UNITS':np.int8\n",
        "                                          ,'SALES':np.float16\n",
        "                                          ,'INDIV_ID':np.float16 # int32 throws error claiming float value\n",
        "                                          }\n",
        "                              ).clean_names()\n",
        "  df = pd.concat([df,sales_to_append], axis = 0)\n",
        "\n",
        "  print('df records: ',f\"{df.shape[0]:,d}\")\n",
        "  print('df memory: ',round(df.memory_usage(deep=True).sum()/1073741824,2))"
      ],
      "metadata": {
        "id": "E95V34hdC6NK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# method 2: read and append one at a time\n",
        "for file in sales_files[1:]:\n",
        "\n",
        "  sales_to_append = pd.read_csv('raw/' + file\n",
        "                                ,sep='|'\n",
        "                                ,usecols=col_list\n",
        "                                #,parse_dates=['DATE']\n",
        "                                #,date_parser=date_parser\n",
        "                                ,dtype = {'STORE_ID':'category'\n",
        "                                          ,'TRAN_ID':np.int32\n",
        "                                          ,'DATE':'category'\n",
        "                                          ,'ARTICLE_ID':np.int32\n",
        "                                          ,'VEHICLE_ID':np.int32\n",
        "                                          ,'UNITS':np.int8\n",
        "                                          ,'SALES':np.float16\n",
        "                                          ,'INDIV_ID':np.float16 # int32 throws error claiming float value\n",
        "                                          }\n",
        "                              ).clean_names()\n",
        "  df = pd.concat([df,sales_to_append], axis = 0)\n",
        "\n",
        "  print('df records: ',f\"{df.shape[0]:,d}\")\n",
        "  print('df memory: ',round(df.memory_usage(deep=True).sum()/1073741824,2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvsHOdOa3I-U",
        "outputId": "18f73146-e275-4163-f23e-77086d81ebce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df records:  30,236,979\n",
            "df memory:  4450\n",
            "df records:  45,867,220\n",
            "df memory:  6750\n",
            "df records:  61,064,891\n",
            "df memory:  8987\n",
            "df records:  76,953,359\n",
            "df memory:  11325\n",
            "df records:  92,895,599\n",
            "df memory:  13672\n",
            "df records:  107,344,695\n",
            "df memory:  15798\n",
            "df records:  123,402,420\n",
            "df memory:  18161\n",
            "df records:  136,649,953\n",
            "df memory:  20111\n",
            "df records:  151,636,603\n",
            "df memory:  22317\n",
            "df records:  166,179,523\n",
            "df memory:  24457\n",
            "df records:  181,771,314\n",
            "df memory:  26751\n",
            "df records:  197,572,120\n",
            "df memory:  29077\n",
            "df records:  212,448,811\n",
            "df memory:  31266\n",
            "df records:  228,051,169\n",
            "df memory:  33562\n",
            "df records:  243,439,535\n",
            "df memory:  35827\n",
            "df records:  259,325,147\n",
            "df memory:  38165\n",
            "df records:  275,085,345\n",
            "df memory:  40484\n",
            "df records:  289,998,142\n",
            "df memory:  42679\n",
            "df records:  305,879,156\n",
            "df memory:  45016\n",
            "df records:  319,921,142\n",
            "df memory:  47083\n",
            "df records:  334,584,443\n",
            "df memory:  49241\n",
            "df records:  349,604,384\n",
            "df memory:  51451\n",
            "df records:  364,486,886\n",
            "df memory:  53641\n",
            "df records:  379,949,398\n",
            "df memory:  55916\n",
            "df records:  395,103,155\n",
            "df memory:  58146\n",
            "df records:  410,640,734\n",
            "df memory:  60433\n",
            "df records:  426,164,747\n",
            "df memory:  62718\n",
            "df records:  441,815,604\n",
            "df memory:  65021\n",
            "df records:  457,296,188\n",
            "df memory:  67299\n",
            "df records:  472,304,873\n",
            "df memory:  69507\n",
            "df records:  487,785,726\n",
            "df memory:  71785\n",
            "df records:  502,523,295\n",
            "df memory:  73954\n",
            "df records:  517,598,203\n",
            "df memory:  76172\n",
            "df records:  531,676,446\n",
            "df memory:  78244\n",
            "df records:  547,070,783\n",
            "df memory:  80509\n",
            "df records:  562,748,384\n",
            "df memory:  82816\n",
            "df records:  578,156,248\n",
            "df memory:  85084\n",
            "df records:  594,631,571\n",
            "df memory:  87508\n",
            "df records:  610,661,706\n",
            "df memory:  89867\n",
            "df records:  627,148,099\n",
            "df memory:  92293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('processed/combined_sales.csv')"
      ],
      "metadata": {
        "id": "ADkFh3yj7KFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "liarweB3-DnY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e1Pv2ANR-CD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def join_data(sales_name_list):\n",
        "    new_list = []\n",
        "    for name in sales_name_list:\n",
        "        # read data files and clean names\n",
        "        sale = pd.read_csv('raw/' + name, sep='|', skiprows=[1]).clean_names()\n",
        "        \n",
        "        # convert store id to string\n",
        "        sale['store_id'] = sale['store_id'].apply(str)\n",
        "     \n",
        "        # merging the data sets together\n",
        "        mega_table = sale.merge(product, on = 'article_id', how = 'left').\\\n",
        "            merge(store, on = 'store_id', how = 'left').\\\n",
        "            merge(individual, on = 'indiv_id', how = 'left').\\\n",
        "            merge(vehicle, on = 'vehicle_id', how = 'left')\n",
        "        \n",
        "        # extracting name for storing data sets\n",
        "        new_name = name[6:]\n",
        "        new_list.append(new_name)\n",
        "        mega_table[\"year\"] = new_name[:4]\n",
        "        mega_table['month'] = new_name[4:-4]\n",
        "        mega_table = mega_table[(mega_table['ah1_res_bus_indc'] == 'R') & (mega_table['supp1_bus_pander'] == 'N') & (mega_table['email_optin_ind'] == 'Y')]\n",
        "        mega_table = mega_table.drop(['ah1_res_bus_indc', 'supp1_bus_pander', 'email_optin_ind'], axis=1)\n",
        "        col_list = list(mega_table.columns)\n",
        "        mega_table.to_csv(\"/data/p_dsi/teams2022/team_1/new_data/\" + new_name)\n",
        "    return new_list, col_list"
      ],
      "metadata": {
        "id": "ADQ1PCPD1HIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QT_6h2-kIloE"
      },
      "outputs": [],
      "source": [
        "def combine_data(sales_list):\n",
        "    data_list, col_list = join_data(sales_list)\n",
        "    df = pd.DataFrame(columns = col_list)\n",
        "    for data_name in data_list: \n",
        "        if os.path.isfile('processed/' + data_name + \".csv\"):\n",
        "            df1 = pd.read_csv('processed/' + data_name + \".csv\")\n",
        "            df = pd.concat([df1, df], axis = 0)\n",
        "            df = df.reset_index(drop = True)\n",
        "    return (df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDvFhBvTIloE"
      },
      "outputs": [],
      "source": [
        "combine_df = combine_data(sales_name_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iymXMu7IloE"
      },
      "outputs": [],
      "source": [
        "combine_df.to_csv(\"/data/p_dsi/teams2022/team_1/new_data/total_dataset.csv\", index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Vnx2THDIloE"
      },
      "source": [
        "There is a high probability for ACCRE to break down during the final combination process. So when you run this notebook, it will be better to use a 4GPU (24 cores) server."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqdlCaWAIloF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
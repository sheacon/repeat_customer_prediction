{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12_join_table_accre"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import janitor\n",
    "from glob import glob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "data_path = '/data/p_dsi/teams2022/bridgestone_data/data/'\n",
    "sales_file_list = glob(data_path + 'sales_2*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"/data/merged_data\"):\n",
    "    os.mkdir(\"/data/merged_data\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Read Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def read_sales(file):\n",
    "    col_list = ['STORE_ID','TRAN_ID','DATE','ARTICLE_ID','INDIV_ID','VEHICLE_ID','UNITS','SALES']\n",
    "    df = pd.read_csv(file\n",
    "                  ,sep='|'\n",
    "                  ,usecols=col_list\n",
    "                  #,parse_dates=['DATE']\n",
    "                  #,date_parser=date_parser\n",
    "                  ,dtype = {'STORE_ID':'category'\n",
    "                            ,'TRAN_ID':np.int32\n",
    "                            ,'DATE':'category'\n",
    "                            ,'ARTICLE_ID':np.int32\n",
    "                            ,'VEHICLE_ID':np.int32\n",
    "                            ,'UNITS':np.int8\n",
    "                            ,'SALES':np.float16\n",
    "                            ,'INDIV_ID':np.float16 # int32 throws error claiming float value\n",
    "                            }\n",
    "                 ).clean_names()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def read_individuals(file):\n",
    "    \n",
    "    col_list = ['MZB_INDIV_ID','EMAIL_OPTIN_IND','AH1_RES_BUS_INDC','SUPP1_BUS_PANDER']\n",
    "    \n",
    "    individuals = pd.read_csv(file\n",
    "                            ,sep=','\n",
    "                            ,usecols=col_list\n",
    "                            ,dtype = {'MZB_INDIV_ID':np.int32\n",
    "                                        ,'EMAIL_OPTIN_IND':'category'\n",
    "                                        ,'AH1_RES_BUS_INDC':'category'\n",
    "                                        ,'SUPP1_BUS_PANDER':'category'} \n",
    "                            ).clean_names()\n",
    "    \n",
    "    individuals.rename(columns={'mzb_indiv_id':'indiv_id'}, inplace=True)\n",
    "\n",
    "    individuals = individuals[(individuals['ah1_res_bus_indc'] == 'R') & (individuals['supp1_bus_pander'] == 'N') & (individuals['email_optin_ind'] == 'Y')]\n",
    "    individuals.drop(['ah1_res_bus_indc', 'supp1_bus_pander', 'email_optin_ind'], axis=1, inplace=True)\n",
    "\n",
    "    return individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def read_products(file):\n",
    "    col_list = ['ARTICLE_ID', 'PROD_GROUP_CODE', 'PROD_GROUP_DESC', 'CATEGORY_CODE',\n",
    "            'CATEGORY_DESC', 'SEGMENT_CODE', 'SEGMENT_DESC', 'CLASS_CODE',\n",
    "            'CLASS_DESC', 'DISCOUNT_FLAG', 'CROSS_SECTION', 'ASPECT_RATIO',\n",
    "            'RIM_SIZE']\n",
    "    products = pd.read_csv(file\n",
    "                            ,sep='|'\n",
    "                            ,usecols=col_list\n",
    "                            ,dtype = {'ARTICLE_ID':np.int32, 'PROD_GROUP_CODE':'category'\n",
    "                                    , 'PROD_GROUP_DESC':'category', 'CATEGORY_CODE':'category'\n",
    "                                    ,'CATEGORY_DESC':'category', 'SEGMENT_CODE':'category'\n",
    "                                    , 'SEGMENT_DESC':'category', 'CLASS_CODE':'category'\n",
    "                                    , 'CLASS_DESC':'category', 'DISCOUNT_FLAG':'category'\n",
    "                                    , 'CROSS_SECTION':'category', 'ASPECT_RATIO':'category',\n",
    "                                    'RIM_SIZE':'category'}\n",
    "                            ).clean_names()\n",
    "\n",
    "    return products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def read_stores(file):\n",
    "    col_list = ['STORE_ID','STATE_CODE','ZIP_CODE','MSA']\n",
    "    stores = pd.read_csv(file\n",
    "                        ,sep='|'\n",
    "                        ,usecols=col_list\n",
    "                        ,dtype = {'STORE_ID':'category'\n",
    "                                    ,'STATE_CODE':'category'\n",
    "                                    ,'ZIP_CODE':'category'\n",
    "                                    ,'MSA':'category'}\n",
    "                        ).clean_names()\n",
    "\n",
    "    return stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def read_vehicles(file):\n",
    "    col_list = ['VEHICLE_ID','MAKE','MODEL','SUB_MODEL','MODEL_YEAR']\n",
    "    vehicles = pd.read_csv(file\n",
    "                            ,sep='|'\n",
    "                            ,usecols=col_list\n",
    "                            ,dtype = {'VEHICLE_ID':np.int32\n",
    "                                    ,'MAKE':'category'\n",
    "                                    ,'MODEL':'category'\n",
    "                                    ,'SUB_MODEL':'category'\n",
    "                                    ,'MODEL_YEAR':np.int16}\n",
    "                            ).clean_names()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# read non-sales tables\n",
    "individual = read_individuals(data_path + '/individual.csv')\n",
    "product = read_products(data_path + '/product.csv')\n",
    "store = read_stores(data_path + '/store.csv')\n",
    "vehicle = read_vehicles(data_path + '/vehicle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# joined tables for each sales month\n",
    "\n",
    "new_file_list = []\n",
    "\n",
    "for file in sales_file_list:\n",
    "    # read data files and clean names\n",
    "    sale = read_sales(data_path + \"/\" + file)\n",
    "    \n",
    "    # merge tables\n",
    "    mega_table = sale.merge(product, on = 'article_id', how = 'inner').\\\n",
    "        merge(store, on = 'store_id', how = 'inner').\\\n",
    "        merge(individual, on = 'indiv_id', how = 'inner').\\\n",
    "        merge(vehicle, on = 'vehicle_id', how = 'inner')\n",
    "    col_list = list(mega_table.columns)\n",
    "    \n",
    "    # new file name and date fields\n",
    "    new_filename = file[6:]\n",
    "    new_file_list.append(new_filename)\n",
    "    mega_table[\"year\"] = new_filename[:4]\n",
    "    mega_table['month'] = new_filename[4:-4]\n",
    "    mega_table.to_parquet(\"data/merged_data/\" + new_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# all the data\n",
    "\n",
    "df = pd.DataFrame(columns = col_list)\n",
    "for file in new_file_list: \n",
    "    if os.path.isfile(\"/data/merged_data/\" + file + \".csv\"):\n",
    "        df1 = pd.read_parquet(\"/data/merged_data/\" + file + \".csv\")\n",
    "        df = pd.concat([df1, df], axis = 0)\n",
    "        df = df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "df.to_parquet(\"data/merged_data/total_dataset.parquet\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

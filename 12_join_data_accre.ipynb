{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12_join_table_accre\n",
    "> Loading the data on accre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import janitor\n",
    "from sklearn.model_selection import train_test_split\n",
    "# must install janitor package with the following shell command:\n",
    "# 'pip install --user pyjanitor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# It may be helpful to use following command to install janitor on ACCRE:\n",
    "#!conda install -c conda-forge/label/gcc7 pyjanitor -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "data_path = '/data/p_dsi/teams2022/bridgestone_data/data'\n",
    "name_list = os.listdir(data_path)\n",
    "sales_name_list = [x for x in name_list if x[0:7]=='sales_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"/data/p_dsi/teams2022/team_1/new_data\"):\n",
    "    os.mkdir(\"/data/p_dsi/teams2022/team_1/new_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def read_sales(file):\n",
    "    col_list = ['STORE_ID','TRAN_ID','DATE','ARTICLE_ID','INDIV_ID','VEHICLE_ID','UNITS','SALES']\n",
    "    df = pd.read_csv(file\n",
    "                  ,sep='|'\n",
    "                  ,usecols=col_list\n",
    "                  #,parse_dates=['DATE']\n",
    "                  #,date_parser=date_parser\n",
    "                  ,dtype = {'STORE_ID':'category'\n",
    "                            ,'TRAN_ID':np.int32\n",
    "                            ,'DATE':'category'\n",
    "                            ,'ARTICLE_ID':np.int32\n",
    "                            ,'VEHICLE_ID':np.int32\n",
    "                            ,'UNITS':np.int8\n",
    "                            ,'SALES':np.float16\n",
    "                            ,'INDIV_ID':np.float16 # int32 throws error claiming float value\n",
    "                            }\n",
    "                 ).clean_names()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def read_individuals(file):\n",
    "    col_list = ['MZB_INDIV_ID','EMAIL_OPTIN_IND','AH1_RES_BUS_INDC','SUPP1_BUS_PANDER']\n",
    "    individuals = pd.read_csv(file\n",
    "                            ,sep=','\n",
    "                            ,usecols=col_list\n",
    "                            ,dtype = {'MZB_INDIV_ID':np.int32\n",
    "                                        ,'EMAIL_OPTIN_IND':'category'\n",
    "                                        ,'AH1_RES_BUS_INDC':'category'\n",
    "                                        ,'SUPP1_BUS_PANDER':'category'} \n",
    "                            ).clean_names()\n",
    "    individuals.rename(columns={'mzb_indiv_id':'indiv_id'}, inplace=True)\n",
    "\n",
    "    return individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def read_products(file):\n",
    "    col_list = ['ARTICLE_ID', 'PROD_GROUP_CODE', 'PROD_GROUP_DESC', 'CATEGORY_CODE',\n",
    "            'CATEGORY_DESC', 'SEGMENT_CODE', 'SEGMENT_DESC', 'CLASS_CODE',\n",
    "            'CLASS_DESC', 'DISCOUNT_FLAG', 'CROSS_SECTION', 'ASPECT_RATIO',\n",
    "            'RIM_SIZE']\n",
    "    products = pd.read_csv(file\n",
    "                            ,sep='|'\n",
    "                            ,usecols=col_list\n",
    "                            ,dtype = {'ARTICLE_ID':np.int32, 'PROD_GROUP_CODE':'category'\n",
    "                                    , 'PROD_GROUP_DESC':'category', 'CATEGORY_CODE':'category'\n",
    "                                    ,'CATEGORY_DESC':'category', 'SEGMENT_CODE':'category'\n",
    "                                    , 'SEGMENT_DESC':'category', 'CLASS_CODE':'category'\n",
    "                                    , 'CLASS_DESC':'category', 'DISCOUNT_FLAG':'category'\n",
    "                                    , 'CROSS_SECTION':'category', 'ASPECT_RATIO':'category',\n",
    "                                    'RIM_SIZE':'category'}\n",
    "                            ).clean_names()\n",
    "\n",
    "    return products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def read_stores(file):\n",
    "    col_list = ['STORE_ID','STATE_CODE','ZIP_CODE','MSA']\n",
    "    stores = pd.read_csv(file\n",
    "                        ,sep='|'\n",
    "                        ,usecols=col_list\n",
    "                        ,dtype = {'STORE_ID':'category'\n",
    "                                    ,'STATE_CODE':'category'\n",
    "                                    ,'ZIP_CODE':'category'\n",
    "                                    ,'MSA':'category'}\n",
    "                        ).clean_names()\n",
    "\n",
    "    return stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def read_vehicles(file):\n",
    "    col_list = ['VEHICLE_ID','MAKE','MODEL','SUB_MODEL','MODEL_YEAR']\n",
    "    vehicles = pd.read_csv(file\n",
    "                            ,sep='|'\n",
    "                            ,usecols=col_list\n",
    "                            ,dtype = {'VEHICLE_ID':np.int32\n",
    "                                    ,'MAKE':'category'\n",
    "                                    ,'MODEL':'category'\n",
    "                                    ,'SUB_MODEL':'category'\n",
    "                                    ,'MODEL_YEAR':np.int16}\n",
    "                            ).clean_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def join_data(sales_name_list):\n",
    "    \n",
    "    new_list = []\n",
    "\n",
    "    individual = read_individuals(data_path + '/individual.csv')\n",
    "    product = read_products(data_path + '/product.csv')\n",
    "    store = read_stores(data_path + '/store.csv')\n",
    "    vehicle = read_vehicles(data_path + '/vehicle.csv')\n",
    "\n",
    "    for name in sales_name_list:\n",
    "        # read data files and clean names\n",
    "        sale = read_sales(data_path + \"/\" + name)\n",
    "        \n",
    "        # merging the data sets together\n",
    "        mega_table = sale.merge(product, on = 'article_id', how = 'left').\\\n",
    "            merge(store, on = 'store_id', how = 'left').\\\n",
    "            merge(individual, on = 'indiv_id', how = 'left').\\\n",
    "            merge(vehicle, on = 'vehicle_id', how = 'left')\n",
    "        \n",
    "        # extracting name for storing data sets\n",
    "        new_name = name[6:]\n",
    "        new_list.append(new_name)\n",
    "        mega_table[\"year\"] = new_name[:4]\n",
    "        mega_table['month'] = new_name[4:-4]\n",
    "        mega_table = mega_table[(mega_table['ah1_res_bus_indc'] == 'R') & (mega_table['supp1_bus_pander'] == 'N') & (mega_table['email_optin_ind'] == 'Y')]\n",
    "        mega_table = mega_table.drop(['ah1_res_bus_indc', 'supp1_bus_pander', 'email_optin_ind'], axis=1)\n",
    "        col_list = list(mega_table.columns)\n",
    "        mega_table.to_csv(\"/data/p_dsi/teams2022/team_1/new_data/\" + new_name)\n",
    "    return new_list, col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def combine_data(sales_list):\n",
    "    data_list, col_list = join_data(sales_list)\n",
    "    df = pd.DataFrame(columns = col_list)\n",
    "    for data_name in data_list: \n",
    "        if os.path.isfile(\"/data/p_dsi/teams2022/team_1/new_data/\" + data_name + \".csv\"):\n",
    "            df1 = pd.read_csv(\"/data/p_dsi/teams2022/team_1/new_data/\" + data_name + \".csv\")\n",
    "            df = pd.concat([df1, df], axis = 0)\n",
    "            df = df.reset_index(drop = True)\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "combine_df = combine_data(sales_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "combine_df.to_csv(\"/data/p_dsi/teams2022/team_1/new_data/total_dataset.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a high probability for ACCRE to break down during the final combination process. So when you run this notebook, it will be better to use a 4GPU (24 cores) server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

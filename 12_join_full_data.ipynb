{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8u1higzYIln_"
      },
      "source": [
        "# 12_join_table_accre\n",
        "> Loading the data on accre"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check system specs\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print('Connected to a GPU')\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime: {:.1f} gigabytes of available RAM'.format(ram_gb))\n",
        "else:\n",
        "  print('Using a high-RAM runtime: {:.1f} gigabytes of available RAM'.format(ram_gb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xojTL10R1AQt",
        "outputId": "dd96036b-e24a-4d63-b3ff-018c4dcc2473"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not connected to a GPU\n",
            "Using a high-RAM runtime: 27.3 gigabytes of available RAM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyjanitor==0.23.1"
      ],
      "metadata": {
        "id": "dU1caunPyrcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "689iQwrFIloB"
      },
      "outputs": [],
      "source": [
        "# import packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import janitor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "     \n",
        "# navigate to directory\n",
        "%cd /content/gdrive/MyDrive/Projects/repeat_customers/data"
      ],
      "metadata": {
        "id": "llahQjbBIyJG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33876255-8fdd-43f4-8d21-900ffaf9bcf1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/MyDrive/Projects/repeat_customers/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cU9IA-2GIloD"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('processed/'):\n",
        "    os.mkdir('processed/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read in non-sales data\n",
        "individual = pd.read_csv('raw/individual.csv', sep=',').clean_names()\n",
        "product = pd.read_csv('raw/product.csv', sep='|').clean_names()\n",
        "store = pd.read_csv('raw/store.csv', sep='|').clean_names()\n",
        "vehicle = pd.read_csv('raw/vehicle.csv', sep='|').clean_names()"
      ],
      "metadata": {
        "id": "di_ad2r70Ift"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data formats and column names\n",
        "store['store_id'] = store['store_id'].apply(str)\n",
        "store['zip_code'] = store['zip_code'].apply(str)\n",
        "individual.rename(columns={'mzb_indiv_id':'indiv_id'}, inplace=True)"
      ],
      "metadata": {
        "id": "slWfR4a21S9s"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create list of sales files\n",
        "sales_files = [i for i in os.listdir('raw/') if 'sales_' in i]"
      ],
      "metadata": {
        "id": "fn6BQbca38Vj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load initial sales file\n",
        "df = pd.read_csv('raw/' + sales_files[0], sep='|').clean_names()\n",
        "print(f\"{df.shape[0]:,d}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7FFQHnY4ebR",
        "outputId": "70049ec0-9c2b-43d2-fae0-581bb1f58c84"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14,804,703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# combine all sales\n",
        "for file in sales_files[1:]:\n",
        "\n",
        "  sales_to_append = pd.read_csv('raw/' + file, sep='|').clean_names()\n",
        "  print(file,': ',f\"{sales_to_append.shape[0]:,d}\")\n",
        "  \n",
        "  df = pd.concat([df,sales_to_append], axis = 0)\n",
        "  print('df: ',f\"{df.shape[0]:,d}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvsHOdOa3I-U",
        "outputId": "de9cf23e-6227-4b56-955c-a67a2742f9cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sales_20181031.csv :  15432276\n",
            "df:  30236979\n",
            "sales_20180831.csv :  15630241\n",
            "df:  45867220\n",
            "sales_20180731.csv :  15197671\n",
            "df:  61064891\n",
            "sales_20180630.csv :  15888468\n",
            "df:  76953359\n",
            "sales_20180531.csv :  15942240\n",
            "df:  92895599\n",
            "sales_20180430.csv :  14449096\n",
            "df:  107344695\n",
            "sales_20180331.csv :  16057725\n",
            "df:  123402420\n",
            "sales_20180228.csv :  13247533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('processed/combined_sales.csv')"
      ],
      "metadata": {
        "id": "ADkFh3yj7KFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "liarweB3-DnY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e1Pv2ANR-CD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def join_data(sales_name_list):\n",
        "    new_list = []\n",
        "    for name in sales_name_list:\n",
        "        # read data files and clean names\n",
        "        sale = pd.read_csv('raw/' + name, sep='|', skiprows=[1]).clean_names()\n",
        "        \n",
        "        # convert store id to string\n",
        "        sale['store_id'] = sale['store_id'].apply(str)\n",
        "     \n",
        "        # merging the data sets together\n",
        "        mega_table = sale.merge(product, on = 'article_id', how = 'left').\\\n",
        "            merge(store, on = 'store_id', how = 'left').\\\n",
        "            merge(individual, on = 'indiv_id', how = 'left').\\\n",
        "            merge(vehicle, on = 'vehicle_id', how = 'left')\n",
        "        \n",
        "        # extracting name for storing data sets\n",
        "        new_name = name[6:]\n",
        "        new_list.append(new_name)\n",
        "        mega_table[\"year\"] = new_name[:4]\n",
        "        mega_table['month'] = new_name[4:-4]\n",
        "        mega_table = mega_table[(mega_table['ah1_res_bus_indc'] == 'R') & (mega_table['supp1_bus_pander'] == 'N') & (mega_table['email_optin_ind'] == 'Y')]\n",
        "        mega_table = mega_table.drop(['ah1_res_bus_indc', 'supp1_bus_pander', 'email_optin_ind'], axis=1)\n",
        "        col_list = list(mega_table.columns)\n",
        "        mega_table.to_csv(\"/data/p_dsi/teams2022/team_1/new_data/\" + new_name)\n",
        "    return new_list, col_list"
      ],
      "metadata": {
        "id": "ADQ1PCPD1HIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QT_6h2-kIloE"
      },
      "outputs": [],
      "source": [
        "def combine_data(sales_list):\n",
        "    data_list, col_list = join_data(sales_list)\n",
        "    df = pd.DataFrame(columns = col_list)\n",
        "    for data_name in data_list: \n",
        "        if os.path.isfile('processed/' + data_name + \".csv\"):\n",
        "            df1 = pd.read_csv('processed/' + data_name + \".csv\")\n",
        "            df = pd.concat([df1, df], axis = 0)\n",
        "            df = df.reset_index(drop = True)\n",
        "    return (df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDvFhBvTIloE"
      },
      "outputs": [],
      "source": [
        "combine_df = combine_data(sales_name_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iymXMu7IloE"
      },
      "outputs": [],
      "source": [
        "combine_df.to_csv(\"/data/p_dsi/teams2022/team_1/new_data/total_dataset.csv\", index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Vnx2THDIloE"
      },
      "source": [
        "There is a high probability for ACCRE to break down during the final combination process. So when you run this notebook, it will be better to use a 4GPU (24 cores) server."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqdlCaWAIloF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12_join_table_accre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "#import janitor\n",
    "from glob import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "data_path = '/data/p_dsi/teams2022/bridgestone_data/data/'\n",
    "sales_file_list = glob(data_path + 'sales_2*.csv')\n",
    "local_path = '/home/conawws1/repeat_customers/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(local_path + \"data/merged_data\"):\n",
    "    os.mkdir(local_path + \"data/merged_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Read Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def read_sales(file):\n",
    "    col_list = ['STORE_ID','TRAN_ID','DATE','ARTICLE_ID','INDIV_ID','VEHICLE_ID','UNITS','SALES']\n",
    "    df = pd.read_csv(file\n",
    "                  ,sep='|'\n",
    "                  ,usecols=col_list\n",
    "                  #,parse_dates=['DATE']\n",
    "                  #,date_parser=date_parser\n",
    "                  ,dtype = {'STORE_ID':'category'\n",
    "                            ,'TRAN_ID':np.int32\n",
    "                            ,'DATE':'category'\n",
    "                            ,'ARTICLE_ID':np.int32\n",
    "                            ,'INDIV_ID':np.float16 # int32 throws error claiming float value\n",
    "                            ,'VEHICLE_ID':np.int32\n",
    "                            ,'UNITS':np.int8\n",
    "                            ,'SALES':np.float16\n",
    "                            }\n",
    "                 )\n",
    "    df.columns = ['store_id', 'tran_id', 'date', 'article_id','indiv_id','vehicle_id', 'units', 'sales']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def read_individuals(file):\n",
    "    \n",
    "    col_list = ['MZB_INDIV_ID','EMAIL_OPTIN_IND','AH1_RES_BUS_INDC','SUPP1_BUS_PANDER']\n",
    "    \n",
    "    individuals = pd.read_csv(file\n",
    "                            ,sep=','\n",
    "                            ,usecols=col_list\n",
    "                            ,dtype = {'MZB_INDIV_ID':np.float16\n",
    "                                        ,'EMAIL_OPTIN_IND':'category'\n",
    "                                        ,'AH1_RES_BUS_INDC':'category'\n",
    "                                        ,'SUPP1_BUS_PANDER':'category'\n",
    "                                     } \n",
    "                            )\n",
    "    \n",
    "    individuals.columns = ['indiv_id', 'email_optin_ind', 'ah1_res_bus_indc','supp1_bus_pander']\n",
    "\n",
    "    individuals = individuals[(individuals['ah1_res_bus_indc'] == 'R') & (individuals['supp1_bus_pander'] == 'N') & (individuals['email_optin_ind'] == 'Y')]\n",
    "    individuals.drop(['ah1_res_bus_indc', 'supp1_bus_pander', 'email_optin_ind'], axis=1, inplace=True)\n",
    "\n",
    "    return individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def read_products(file):\n",
    "    col_list = ['ARTICLE_ID', 'PROD_GROUP_CODE', 'PROD_GROUP_DESC', 'CATEGORY_CODE',\n",
    "            'CATEGORY_DESC', 'SEGMENT_CODE', 'SEGMENT_DESC', 'CLASS_CODE',\n",
    "            'CLASS_DESC', 'DISCOUNT_FLAG', 'CROSS_SECTION', 'ASPECT_RATIO',\n",
    "            'RIM_SIZE']\n",
    "    products = pd.read_csv(file\n",
    "                            ,sep='|'\n",
    "                            ,usecols=col_list\n",
    "                            ,dtype = {'ARTICLE_ID':np.int32, 'PROD_GROUP_CODE':'category'\n",
    "                                    , 'PROD_GROUP_DESC':'category', 'CATEGORY_CODE':'category'\n",
    "                                    ,'CATEGORY_DESC':'category', 'SEGMENT_CODE':'category'\n",
    "                                    , 'SEGMENT_DESC':'category', 'CLASS_CODE':'category'\n",
    "                                    , 'CLASS_DESC':'category', 'DISCOUNT_FLAG':'category'\n",
    "                                    , 'CROSS_SECTION':'category', 'ASPECT_RATIO':'category',\n",
    "                                    'RIM_SIZE':'category'\n",
    "                                     }\n",
    "                            )\n",
    "\n",
    "    products.columns = ['article_id', 'prod_group_code', 'prod_group_desc', 'category_code',\n",
    "                       'category_desc', 'segment_code', 'segment_desc', 'class_code',\n",
    "                       'class_desc', 'discount_flag', 'cross_section', 'aspect_ratio',\n",
    "                       'rim_size']\n",
    "    \n",
    "    return products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def read_stores(file):\n",
    "    col_list = ['STORE_ID','STATE_CODE','ZIP_CODE','MSA']\n",
    "    stores = pd.read_csv(file\n",
    "                        ,sep='|'\n",
    "                        ,usecols=col_list\n",
    "                        ,dtype = {'STORE_ID':'category'\n",
    "                                    ,'STATE_CODE':'category'\n",
    "                                    ,'ZIP_CODE':'category'\n",
    "                                    ,'MSA':'category'\n",
    "                                 }\n",
    "                        )\n",
    "\n",
    "    stores.columns = ['store_id', 'state_code', 'zip_code', 'msa']\n",
    "    \n",
    "    return stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def read_vehicles(file):\n",
    "    col_list = ['VEHICLE_ID','MAKE','MODEL','SUB_MODEL','MODEL_YEAR']\n",
    "    vehicles = pd.read_csv(file\n",
    "                            ,sep='|'\n",
    "                            ,usecols=col_list\n",
    "                            ,dtype = {'VEHICLE_ID':np.int32\n",
    "                                    ,'MAKE':'category'\n",
    "                                    ,'MODEL':'category'\n",
    "                                    ,'SUB_MODEL':'category'\n",
    "                                    ,'MODEL_YEAR':np.int16\n",
    "                                     }\n",
    "                            )\n",
    "    \n",
    "    vehicles.columns = ['vehicle_id', 'make', 'model', 'sub_model', 'model_year']\n",
    "    \n",
    "    return vehicles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual = read_individuals(data_path + '/individual.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# read non-sales tables\n",
    "individual = read_individuals(data_path + '/individual.csv')\n",
    "product = read_products(data_path + '/product.csv')\n",
    "store = read_stores(data_path + '/store.csv')\n",
    "vehicle = read_vehicles(data_path + '/vehicle.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Sales File and Merge Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['STORE_ID', 'TRAN_ID', 'DATE', 'ARTICLE_ID', 'INDIV_ID', 'VEHICLE_ID',\n",
      "       'UNITS', 'SALES'],\n",
      "      dtype='object')\n",
      "2.04 min\n"
     ]
    }
   ],
   "source": [
    "# read sales file for one month\n",
    "file = sales_file_list[0]\n",
    "sale = read_sales(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.54 min\n"
     ]
    }
   ],
   "source": [
    "# joined tables for each sales month\n",
    "\n",
    "new_file_list = []\n",
    "\n",
    "# merge ancillary tables\n",
    "mega_table = sale.merge(product, on = 'article_id', how = 'inner').\\\n",
    "    merge(store, on = 'store_id', how = 'inner').\\\n",
    "    merge(individual, on = 'indiv_id', how = 'inner').\\\n",
    "    merge(vehicle, on = 'vehicle_id', how = 'inner')\n",
    "col_list = list(mega_table.columns)\n",
    "\n",
    "# date fields\n",
    "date = file[-12:-4]\n",
    "mega_table[\"year\"] = date[:4]\n",
    "mega_table['month'] = date[4:-2]\n",
    "\n",
    "# new file name\n",
    "new_filename = date + '.csv'\n",
    "new_file_list.append(new_filename)\n",
    "\n",
    "\n",
    "# write out merged file for one month\n",
    "\n",
    "mega_table.to_csv(local_path + \"data/merged_data/\" + new_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>tran_id</th>\n",
       "      <th>date</th>\n",
       "      <th>article_id</th>\n",
       "      <th>units</th>\n",
       "      <th>sales</th>\n",
       "      <th>indiv_id</th>\n",
       "      <th>prod_group_code</th>\n",
       "      <th>prod_group_desc</th>\n",
       "      <th>category_code</th>\n",
       "      <th>...</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>rim_size</th>\n",
       "      <th>state_code</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>msa</th>\n",
       "      <th>vehicle_id</th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>sub_model</th>\n",
       "      <th>model_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [store_id, tran_id, date, article_id, units, sales, indiv_id, prod_group_code, prod_group_desc, category_code, category_desc, segment_code, segment_desc, class_code, class_desc, discount_flag, cross_section, aspect_ratio, rim_size, state_code, zip_code, msa, vehicle_id, make, model, sub_model, model_year]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 27 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mega_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales Files and Merge Loop (after test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# joined tables for each sales month\n",
    "\n",
    "new_file_list = []\n",
    "\n",
    "for file in sales_file_list:\n",
    "    \n",
    "    # read sales file for one month\n",
    "    sale = read_sales(data_path + \"/\" + file)\n",
    "    \n",
    "    # merge ancillary tables\n",
    "    mega_table = sale.merge(product, on = 'article_id', how = 'inner').\\\n",
    "        merge(store, on = 'store_id', how = 'inner').\\\n",
    "        merge(individual, on = 'indiv_id', how = 'inner').\\\n",
    "        merge(vehicle, on = 'vehicle_id', how = 'inner')\n",
    "    col_list = list(mega_table.columns)\n",
    "    \n",
    "    # define new file name and date fields\n",
    "    new_filename = file[6:]\n",
    "    new_file_list.append(new_filename)\n",
    "    mega_table[\"year\"] = new_filename[:4]\n",
    "    mega_table['month'] = new_filename[4:-4]\n",
    "    \n",
    "    # write out merged file for one month\n",
    "    mega_table.to_parquet(local_path + \"data/merged_data/\" + new_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# all the data\n",
    "\n",
    "df = pd.DataFrame(columns = col_list)\n",
    "for file in new_file_list: \n",
    "    if os.path.isfile(local_path + \"/data/merged_data/\" + file + \".csv\"):\n",
    "        df1 = pd.read_parquet(local_path + \"/data/merged_data/\" + file + \".csv\")\n",
    "        df = pd.concat([df1, df], axis = 0)\n",
    "        df = df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "df.to_parquet(local_path + \"data/merged_data/total_dataset.parquet\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
